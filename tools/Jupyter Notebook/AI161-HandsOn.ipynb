{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AICORE_SERVICE_KEY = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "groupID = \"\"\n",
    "scenario = \"AI-161-\"+groupID\n",
    "targetModel = \"gpt-4o-mini:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fca7f8",
   "metadata": {},
   "source": [
    "# Dependencies and Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a56d0e",
   "metadata": {},
   "source": [
    "## AI Core Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc3b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fetch_credentials(resource_group: str = \"default\"):\n",
    "    ai_core_key = json.loads(AICORE_SERVICE_KEY)\n",
    "    return {\n",
    "        \"base_url\": ai_core_key['serviceurls']['AI_API_URL'],\n",
    "        \"auth_url\": ai_core_key[\"url\"],\n",
    "        \"client_id\": ai_core_key[\"clientid\"],\n",
    "        \"client_secret\": ai_core_key[\"clientsecret\"],\n",
    "        \"resource_group\": resource_group\n",
    "\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a928d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://int.repositories.cloud.sap/artifactory/api/pypi/proxy-deploy-releases-hyperspace-pypi/simple\n",
      "Requirement already satisfied: rich in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (13.5.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: sap-ai-sdk-gen in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.6.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich) (2.16.1)\n",
      "Requirement already satisfied: langchain-openai>=0.3.7 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (0.3.33)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (8.1.7)\n",
      "Requirement already satisfied: overloading==0.5.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (0.5.0)\n",
      "Requirement already satisfied: pydantic~=2.11.4 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (2.11.9)\n",
      "Requirement already satisfied: dacite>=1.8.1 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (1.8.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (23.2)\n",
      "Requirement already satisfied: sap-ai-sdk-core>=3.0.11 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (3.0.11)\n",
      "Requirement already satisfied: openai>=1.58.1 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (1.109.1)\n",
      "Requirement already satisfied: langchain~=0.3.25 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (0.3.27)\n",
      "Requirement already satisfied: langchain-community~=0.3.25 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (0.3.30)\n",
      "Requirement already satisfied: h11>=0.16.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (0.16.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-gen) (0.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.1.7->sap-ai-sdk-gen) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->sap-ai-sdk-gen) (4.0.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->sap-ai-sdk-gen) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->sap-ai-sdk-gen) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->sap-ai-sdk-gen) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->sap-ai-sdk-gen) (1.3.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain~=0.3.25->sap-ai-sdk-gen) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain~=0.3.25->sap-ai-sdk-gen) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain~=0.3.25->sap-ai-sdk-gen) (0.4.31)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain~=0.3.25->sap-ai-sdk-gen) (2.0.20)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain~=0.3.25->sap-ai-sdk-gen) (2.32.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community~=0.3.25->sap-ai-sdk-gen) (3.8.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community~=0.3.25->sap-ai-sdk-gen) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community~=0.3.25->sap-ai-sdk-gen) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community~=0.3.25->sap-ai-sdk-gen) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community~=0.3.25->sap-ai-sdk-gen) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community~=0.3.25->sap-ai-sdk-gen) (1.26.4)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai>=0.3.7->sap-ai-sdk-gen) (0.8.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.58.1->sap-ai-sdk-gen) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.58.1->sap-ai-sdk-gen) (0.5.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.58.1->sap-ai-sdk-gen) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.58.1->sap-ai-sdk-gen) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic~=2.11.4->sap-ai-sdk-gen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic~=2.11.4->sap-ai-sdk-gen) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic~=2.11.4->sap-ai-sdk-gen) (0.4.1)\n",
      "Requirement already satisfied: sap-ai-sdk-base==3.1.6 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-core>=3.0.11->sap-ai-sdk-gen) (3.1.6)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-base==3.1.6->sap-ai-sdk-core>=3.0.11->sap-ai-sdk-gen) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sap-ai-sdk-base==3.1.6->sap-ai-sdk-core>=3.0.11->sap-ai-sdk-gen) (3.8.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community~=0.3.25->sap-ai-sdk-gen) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community~=0.3.25->sap-ai-sdk-gen) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community~=0.3.25->sap-ai-sdk-gen) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community~=0.3.25->sap-ai-sdk-gen) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community~=0.3.25->sap-ai-sdk-gen) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community~=0.3.25->sap-ai-sdk-gen) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community~=0.3.25->sap-ai-sdk-gen) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community~=0.3.25->sap-ai-sdk-gen) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community~=0.3.25->sap-ai-sdk-gen) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain~=0.3.25->sap-ai-sdk-gen) (1.33)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.17->langchain~=0.3.25->sap-ai-sdk-gen) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.17->langchain~=0.3.25->sap-ai-sdk-gen) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.17->langchain~=0.3.25->sap-ai-sdk-gen) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community~=0.3.25->sap-ai-sdk-gen) (1.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain~=0.3.25->sap-ai-sdk-gen) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain~=0.3.25->sap-ai-sdk-gen) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.3.7->sap-ai-sdk-gen) (2023.8.8)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain~=0.3.25->sap-ai-sdk-gen) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\i588417\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community~=0.3.25->sap-ai-sdk-gen) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install rich PyYAML sap-ai-sdk-gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d814660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy import get_proxy_client, GenAIHubProxyClient\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "from ai_api_client_sdk.models.input_artifact_binding import InputArtifactBinding\n",
    "from ai_api_client_sdk.models.parameter_binding import ParameterBinding\n",
    "from ai_api_client_sdk.models.artifact import Artifact\n",
    "from ai_api_client_sdk.models.label import Label\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "client = GenAIHubProxyClient(**fetch_credentials())\n",
    "deployments = client.ai_core_client.deployment.query()\n",
    "orchestration_deployment = None\n",
    "for deployment in deployments.resources:\n",
    "    if deployment.scenario_id == \"orchestration\":\n",
    "        orchestration_deployment = deployment\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd135e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def check_model_availability(latest_only: bool = True, filter_list = None):\n",
    "\n",
    "    url = client.ai_core_client.base_url + \"/lm/scenarios/foundation-models/models\"\n",
    "    response = requests.get(url=url, headers=client.request_header)\n",
    "    models = {}\n",
    "    for model in response.json()['resources']:\n",
    "        if  not any([scenario[\"executableId\"] == \"orchestration\" for scenario in model[\"allowedScenarios\"]]):\n",
    "            continue\n",
    "        if filter_list is not None and model[\"model\"] not in filter_list:\n",
    "            continue\n",
    "        models[model[\"model\"]] = []\n",
    "        for version in model[\"versions\"]:\n",
    "            if not any([v == \"text-generation\" for v in version.get(\"capabilities\", [])]):\n",
    "                continue\n",
    "            if not latest_only or version[\"isLatest\"]:\n",
    "                models[model[\"model\"]].append(version[\"name\"])\n",
    "            if version[\"isLatest\"]:\n",
    "                models[model[\"model\"]].append(\"latest\")\n",
    "\n",
    "    return [f'{k}:{v}' for k, vv in models.items() for v in vv if len(vv) > 0 ]\n",
    "\n",
    "filter_list=[\n",
    "    'gpt-5',\n",
    "    'gpt-5-mini',\n",
    "    'gpt-5-nano',\n",
    "    'gpt-4.1',\n",
    "    'gpt-4.1-mini',\n",
    "    'gpt-4.1-nano',\n",
    "    'gpt-4o',\n",
    "    'gpt-4o-mini',\n",
    "    'gemini-2.5-pro',\n",
    "    'gemini-2.5-flash',\n",
    "    'anthropic--claude-4-sonnet',\n",
    "    'anthropic--claude-4-opus'\n",
    "]\n",
    "\n",
    "SUPPORTED_MODELS = check_model_availability(filter_list=filter_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd126d",
   "metadata": {},
   "source": [
    "## Helper Functions Prompt Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9c8ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import PlaceHolder\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "from gen_ai_hub.prompt_registry.models.prompt_template import PromptTemplateSpec as PromptTemplateSpec_\n",
    "from gen_ai_hub.prompt_registry.models.prompt_template import PromptTemplate\n",
    "\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.highlighter import RegexHighlighter\n",
    "from rich.theme import Theme\n",
    "from rich.panel import Panel\n",
    "from rich import print\n",
    "\n",
    "class PromptTemplateSpec(BaseModel):\n",
    "    template: List[PromptTemplate]\n",
    "\n",
    "\n",
    "    @property\n",
    "    def placeholders(self):\n",
    "        placeholders = set()\n",
    "        pattern = re.compile(r'\\{\\{\\s*\\?\\s*(\\w+)\\s*\\}\\}')\n",
    "        for message in self.template:\n",
    "            placeholders.update(pattern.findall(message.content))\n",
    "        return placeholders\n",
    "\n",
    "    @classmethod\n",
    "    def from_optimizer_result(cls, input_):\n",
    "        placeholders = input_.get(\"user_message_template_fields\", [])\n",
    "        def replace(msg):\n",
    "            for key in placeholders:\n",
    "                msg = msg.replace(\"{\"+key+\"}\", \"{{?\"+ key + \"}}\")\n",
    "            return msg\n",
    "\n",
    "        return cls(\n",
    "            template=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": replace(input_[\"system_prompt\"]),\n",
    "                },{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": replace(input_[\"user_message_template\"]),\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def escape_curly_brackets(self) -> \"PromptTemplateSpec\":\n",
    "        # 1. Hide each {{?key}} placeholder with a unique token\n",
    "        placeholder_pattern = re.compile(r'\\{\\{\\s*\\?\\s*(\\w+)\\s*\\}\\}')\n",
    "        mapping = {}\n",
    "        counter = 1\n",
    "\n",
    "        def _hide(match):\n",
    "            nonlocal counter\n",
    "            token = f\"__PLACEHOLDER_{counter}__\"\n",
    "            mapping[token] = match.group(0)\n",
    "            counter += 1\n",
    "            return token\n",
    "\n",
    "        new_templates = []\n",
    "        for msg in self.template:\n",
    "            # a) hide custom placeholders\n",
    "            hidden = placeholder_pattern.sub(_hide, msg.content)\n",
    "            # b) escape all remaining braces\n",
    "            escaped = hidden.replace('{', '{{').replace('}', '}}')\n",
    "            # c) restore the original placeholders\n",
    "            print(mapping)\n",
    "            for token, original in mapping.items():\n",
    "                escaped = escaped.replace(token, original)\n",
    "\n",
    "            new_templates.append(PromptTemplate(role=msg.role, content=escaped))\n",
    "\n",
    "        # return a fresh copy\n",
    "        return PromptTemplateSpec(template=new_templates)\n",
    "\n",
    "\n",
    "\n",
    "def fetch_prompt_template(prompt_template: str) -> PromptTemplateSpec:\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    url = f\"{client.ai_core_client.base_url}/lm/promptTemplates\"\n",
    "    scenario, sep, name = prompt_template.partition(\"/\")\n",
    "    if sep:\n",
    "        name, sep, version = name.partition(\":\")\n",
    "    if sep:\n",
    "        body = {\"name\": name,\n",
    "                \"version\": version,\n",
    "                \"scenario\": scenario,\n",
    "                \"includeSpec\": True\n",
    "            }\n",
    "        response =  requests.get(url, headers=headers, params=body)\n",
    "        response.raise_for_status()\n",
    "        response = response.json()\n",
    "        if response[\"count\"] > 0:\n",
    "            response = response[\"resources\"][0]\n",
    "        else:\n",
    "            raise ValueError(f\"Prompt template {name} not found.\")\n",
    "    else:\n",
    "        url += f\"/{prompt_template}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        response = response.json()\n",
    "    return PromptTemplateSpec.model_validate(response[\"spec\"])\n",
    "\n",
    "def load_prompt_template(prompt: str | pathlib.Path | list | dict | PromptTemplateSpec) -> PromptTemplateSpec:\n",
    "    if isinstance(prompt, PromptTemplateSpec):\n",
    "        return prompt\n",
    "    if isinstance(prompt, PromptTemplateSpec_):\n",
    "        return prompt\n",
    "    if isinstance(prompt, (str, pathlib.Path)) and pathlib.Path(prompt).exists():\n",
    "        with open(prompt, \"r\") as f:\n",
    "            prompt = yaml.safe_load(f)\n",
    "    elif isinstance(prompt, str):\n",
    "        return fetch_prompt_template(prompt)\n",
    "    if isinstance(prompt, dict):\n",
    "        # expect dict with keys \"system\" [optional] and \"user\"\n",
    "        messages = []\n",
    "        if \"system\" in prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": prompt[\"system\"]})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt[\"user\"]})\n",
    "        return PromptTemplateSpec(template=messages)\n",
    "    elif isinstance(prompt, list):\n",
    "        # expect list of dicts with keys \"role\" and \"content\"\n",
    "        return PromptTemplateSpec(template=messages)\n",
    "    else:\n",
    "        raise ValueError(\"Prompt must be a string, Path, list or dict\")\n",
    "\n",
    "\n",
    "def push_prompt_template(prompt_template: PromptTemplateSpec,\n",
    "                         prompt_template_name_registry: str,\n",
    "                         prompt_template_version: str,\n",
    "                         scenario: str,\n",
    "                         update=False):\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    url = f\"{client.ai_core_client.base_url}/lm/promptTemplates\"\n",
    "    body = {\"name\": prompt_template_name_registry,\n",
    "            \"version\": prompt_template_version,\n",
    "            \"scenario\": scenario}\n",
    "    res = requests.get(url, headers=headers, params=body)\n",
    "    res.raise_for_status()\n",
    "    res = res.json()\n",
    "    if res[\"count\"] > 0 and not update:\n",
    "        print(f\"Prompt template {prompt_template_name_registry} already exists. Use update=True to update.\")\n",
    "        return res[\"resources\"][0]\n",
    "    # Prepare body\n",
    "\n",
    "    body[\"spec\"] = prompt_template.model_dump()\n",
    "    # Prepare headers\n",
    "    response = requests.post(url, headers=headers, json=body)\n",
    "    # Handle response\n",
    "    if response.status_code == 201:\n",
    "        response = response.json()\n",
    "    elif response.status_code in (400, 409, 413):\n",
    "        # Return error details\n",
    "        raise requests.HTTPError(f\"Upload failed ({response.status_code}): {response.text}\")\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def convert_py_notation(template):\n",
    "    pattern = re.compile(r'\\{\\{\\s*\\?\\s*(\\w+)\\s*\\}\\}')\n",
    "    return pattern.sub(lambda match: \"{\" + match.group(1) + \"}\", template)\n",
    "\n",
    "\n",
    "def validate_prompt(prompt: PromptTemplateSpec):\n",
    "    values = {k: \"???\" for k in prompt.placeholders}\n",
    "\n",
    "    for message in prompt.template:\n",
    "        if message.role == \"user\":\n",
    "            try:\n",
    "                convert_py_notation(message.content).format(**values)\n",
    "            except KeyError as err:\n",
    "                msg = [\"Unexpected key error when running test formatting.\"]\n",
    "                msg += [\"This is most likeyly due to unescaped curly brackets.\"]\n",
    "                msg += [\"You can try fixing this by running `prompt = prompt.escape_curly_brackets()` and use the new prompt template.\"]\n",
    "                raise ValueError(\"\\n\".join(msg)) from err\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TemplateHighlighter(RegexHighlighter):\n",
    "    \"\"\"Apply style to anything that looks like an email.\"\"\"\n",
    "\n",
    "    base_style = \"template.\"\n",
    "    highlights = [r\"(?P<placeholder>\\{\\{\\s*\\?[^\\{\\}\\s]+\\s*\\}\\})\"]\n",
    "\n",
    "highlighter = TemplateHighlighter()\n",
    "theme = Theme({\"template.placeholder\": \"bold magenta\", \"example.email\": \"bold magenta\"})\n",
    "console = Console(highlighter=highlighter, theme=theme)\n",
    "\n",
    "\n",
    "def print_prompt_template(prompt_template: PromptTemplateSpec | str | pathlib.Path, addition: str | None = None):\n",
    "\n",
    "    prompt_template = load_prompt_template(prompt_template)\n",
    "    addition = f' - {addition}' if addition else ''\n",
    "\n",
    "    for message in prompt_template.template:\n",
    "        if message.role == \"system\":\n",
    "            console.print(Panel(highlighter(message.content), title=\"System Message\" + addition, border_style=\"red\"))\n",
    "        elif message.role == \"user\":\n",
    "            console.print(Panel(highlighter(message.content), title=\"User Message\" + addition, border_style=\"green\"))\n",
    "        else:\n",
    "            console.print(Panel(highlighter(message.content), title=\"Assistant Message\" + addition))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd47f90",
   "metadata": {},
   "source": [
    "## Helper Function Dataset and Artifact Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "011fe32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import requests\n",
    "import mimetypes\n",
    "from urllib.parse import quote\n",
    "import pathlib\n",
    "import json\n",
    "\n",
    "\n",
    "def validate_dataset(dataset: str | pathlib.Path | list, expected_keys: None | List[str] = None) -> bool:\n",
    "    if isinstance(dataset, (str, pathlib.Path)):\n",
    "        with open(dataset, \"r\") as f:\n",
    "            try:\n",
    "                dataset = json.load(f)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Invalid JSON in file: {e}\")\n",
    "    if not isinstance(dataset, list):\n",
    "        raise ValueError(\"Dataset must be a list of dictionaries.\")\n",
    "\n",
    "    def validate_item(item: dict, excepted_keys: None | List[str]) -> bool:\n",
    "        excepted_keys = set(excepted_keys) if excepted_keys else None\n",
    "        if set(item.keys()) != {\"fields\", \"answer\"}:\n",
    "            raise ValueError(\"Each item must contain 'fields' and 'answer' keys.\")\n",
    "        if not isinstance(item[\"fields\"], dict):\n",
    "            raise ValueError(\"'fields' must be a dictionary.\")\n",
    "        fields = set(item[\"fields\"].keys())\n",
    "        if excepted_keys is not None:\n",
    "            if fields != excepted_keys:\n",
    "                if fields.difference(excepted_keys):\n",
    "                    raise ValueError(f\"Unexpected keys in 'fields'. Expected: {excepted_keys}, Found: {fields}\")\n",
    "                if excepted_keys.difference(fields):\n",
    "                    raise ValueError(f\"Missing keys in 'fields'. Expected: {excepted_keys}, Found: {fields}\")\n",
    "        if not all([isinstance(k, str) for k in item[\"fields\"].values()]):\n",
    "            raise ValueError(\"All values in 'fields' must be strings.\")\n",
    "        return fields\n",
    "\n",
    "    excepted_keys = expected_keys\n",
    "    for i, item in enumerate(dataset):\n",
    "        if not isinstance(item, dict):\n",
    "            raise ValueError(\"Each item in the dataset must be a dictionary.\")\n",
    "        try:\n",
    "            excepted_keys = validate_item(item, excepted_keys)\n",
    "        except ValueError as e:\n",
    "            raise ValueError(f\"Error in entry {i}\") from e\n",
    "    return True\n",
    "\n",
    "\n",
    "def upload_file(secret: str,\n",
    "                local_path: str | pathlib.Path,\n",
    "                remote_path: str,\n",
    "                overwrite: bool = False,) -> str:\n",
    "    # check if secret exists\n",
    "    secrets = [r.name for r in client.ai_core_client.object_store_secrets.query().resources]\n",
    "    if secret not in secrets:\n",
    "        raise ValueError(f\"Secret '{secret}' not found in object store secrets. Known secrets: {secrets}\")\n",
    "\n",
    "    # Check if local path exists\n",
    "    remote_path = remote_path.lstrip(\"/\")\n",
    "    if \"/\" not in remote_path and not allow_bucket_root:\n",
    "        raise ValueError(\n",
    "            \"Remote path must use subdirectories. Otherwise the whole bucket will be used as an input artifact. Set allow_bucket_root=True to allow this.\"\n",
    "        )\n",
    "\n",
    "    # URL-encode the path parameter\n",
    "    path = f\"{secret}/\" + remote_path.lstrip(\"/\")\n",
    "    encoded_path = quote(path, safe=\"\")\n",
    "    url = f\"{client.ai_core_client.base_url}/lm/dataset/files/{encoded_path}\"\n",
    "    params = {\"overwrite\": str(overwrite).lower()}\n",
    "\n",
    "    # Prepare headers\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/octet-stream\",\n",
    "    }\n",
    "    # Guess MIME type\n",
    "    guessed_type, _ = mimetypes.guess_type(local_path)\n",
    "    if guessed_type:\n",
    "        headers[\"Content-Type\"] = guessed_type\n",
    "\n",
    "    with open(local_path, \"rb\") as f:\n",
    "        response = requests.put(url, params=params, headers=headers, data=f)\n",
    "\n",
    "    # Handle response\n",
    "    if response.status_code == 201:\n",
    "        response = response.json()\n",
    "    elif response.status_code in (400, 409, 413):\n",
    "        # Return error details\n",
    "        raise requests.HTTPError(f\"Upload failed ({response.status_code}): {response.text}\")\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "    return \"/\".join(response[\"url\"].split(\"/\")[:-1])\n",
    "\n",
    "def register_artifact(artifact_name:str,\n",
    "                      artifact_root_path,\n",
    "                      scenario: str,\n",
    "                      artifact_kind: Artifact.Kind,\n",
    "                      description: str):\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/octet-stream\",\n",
    "    }\n",
    "\n",
    "    for artifact in client.ai_core_client.artifact.query().resources:\n",
    "        if artifact_root_path==(artifact.url + \"/\"):\n",
    "            return artifact \n",
    "\n",
    "    # Create new artifact\n",
    "    new_artifact = client.ai_core_client.artifact.create(\n",
    "        name=artifact_name,\n",
    "        kind=artifact_kind,\n",
    "        url=artifact_root_path,\n",
    "        scenario_id=scenario,\n",
    "        description=description,\n",
    "        resource_group=headers[client.ai_core_client.rest_client.resource_group_header]\n",
    "    )\n",
    "    return new_artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03eee81",
   "metadata": {},
   "source": [
    "## Helper Function Execution Result Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e106dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "def fetch_results(execution_id, file_name: str='result-data/results.json'):\n",
    "    response = client.ai_core_client.execution.get(execution_id = execution_id)\n",
    "    if response.status.name not in {'DEAD', 'COMPLETED'}:\n",
    "        raise RuntimeError('Execution not finished!')\n",
    "    path = f\"default/{execution_id}/{file_name}\"\n",
    "    encoded_path = quote(path, safe=\"\")\n",
    "    url = f\"{client.ai_core_client.base_url}/lm/dataset/files/{encoded_path}\"\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()# results = response.json()\n",
    "\n",
    "\n",
    "def print_result(result):\n",
    "    origin_model = result[\"origin_model\"]\n",
    "    table = Table(title=\"Performance\")\n",
    "    table.add_column(\"Model\", justify=\"right\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Pre Optimization\", style=\"magenta\")\n",
    "    table.add_column(\"Post Optimization\", justify=\"right\", style=\"green\")\n",
    "    table.add_row(origin_model[\"model_name\"], f'{origin_model[\"score\"]:.3f}', \"n/a - reference run\")\n",
    "    for m in result[\"target_models\"]:\n",
    "        table.add_row(m[\"model_name\"], f'{m[\"pre_optimization_score\"]:.3f}', f'{m[\"post_optimization_score\"]:.3f}')\n",
    "    console.print(table)\n",
    "    for m in result[\"target_models\"]:\n",
    "        print_prompt_template(PromptTemplateSpec.from_optimizer_result(m), addition=m['model_name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc1d3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import Callable, Optional\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.live import Live\n",
    "from rich.panel import Panel\n",
    "from rich.spinner import Spinner\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "from requests import HTTPError\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Add ERROR, use lowercase color names (Rich style)\n",
    "_STATUS_COLORS = {\n",
    "    \"UNKNOWN\": \"bright_black\",\n",
    "    \"PENDING\": \"yellow\",\n",
    "    \"RUNNING\": \"cyan\",\n",
    "    \"COMPLETED\": \"green\",\n",
    "    \"ERROR\": \"red\",\n",
    "    \"DEAD\": \"red\",\n",
    "    \"STOPPED\": \"red\",\n",
    "}\n",
    "\n",
    "# Define terminal statuses (polling stops on any of these)\n",
    "_TERMINAL_STATUSES = {\"COMPLETED\", \"ERROR\", \"STOPPED\", \"DEAD\"}\n",
    "\n",
    "\n",
    "def _render_status_panel(\n",
    "    execution_id: str,\n",
    "    status: str,\n",
    "    created_at: datetime,\n",
    "    note: Optional[str] = None,\n",
    ") -> Panel:\n",
    "    # Ensure created_at is timezone-aware in UTC\n",
    "    if created_at.tzinfo is None:\n",
    "        created_at = created_at.replace(tzinfo=timezone.utc)\n",
    "\n",
    "    now = datetime.now(timezone.utc)\n",
    "    elapsed = now - created_at\n",
    "\n",
    "    table = Table.grid(padding=(0, 1))\n",
    "    table.add_column(justify=\"right\", style=\"bold\")\n",
    "    table.add_column()\n",
    "\n",
    "    color = _STATUS_COLORS.get(status, \"white\")\n",
    "    table.add_row(\"Execution ID:\", Text(execution_id, style=\"bold\"))\n",
    "    table.add_row(\"Status:\", Text(status, style=f\"bold {color}\"))\n",
    "    table.add_row(\"Elapsed:\", Text(str(elapsed).split(\".\")[0]))  # drop microseconds\n",
    "\n",
    "    if note:\n",
    "        table.add_row(\"Note:\", Text(note, style=\"italic\"))\n",
    "\n",
    "    # Show spinner only for non-terminal states\n",
    "    if status not in _TERMINAL_STATUSES:\n",
    "        spinner = Spinner(\"dots\", text=\"Pollingâ€¦ (Interrupt cell to stop)\")\n",
    "        content = Table.grid()\n",
    "        content.add_row(spinner)\n",
    "        content.add_row(table)\n",
    "        return Panel(content, title=\"Run Status\", border_style=color)\n",
    "    else:\n",
    "        return Panel(table, title=\"Run Status\", border_style=color)\n",
    "\n",
    "\n",
    "def poll_status(\n",
    "    execution_id: str,\n",
    "    client,\n",
    "    *,\n",
    "    interval: float = 30.0,\n",
    "    timeout: Optional[float] = None,\n",
    "    cancel_callback: Optional[Callable[[str], None]] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Block until the execution reaches a terminal state (COMPLETED, ERROR, STOPPED, DEAD),\n",
    "    rendering a live status panel. Interrupt the cell to stop polling; cancel the remote\n",
    "    run via your client if you also want to unblock the run.\n",
    "    \"\"\"\n",
    "    # Get initial execution info (for created_at)\n",
    "    first_resp = client.ai_core_client.execution.get(execution_id=execution_id)\n",
    "    created_at_raw = first_resp.created_at\n",
    "    if not created_at_raw:\n",
    "        raise ValueError(\"Execution response did not include 'created_at'.\")\n",
    "    created_at = (\n",
    "        created_at_raw if isinstance(created_at_raw, datetime)\n",
    "        else datetime.fromisoformat(created_at_raw.replace(\"Z\", \"+00:00\"))\n",
    "    )\n",
    "\n",
    "    note = (\n",
    "        \"This cell is blocking until the run completes or stops. \"\n",
    "        \"To stop polling, interrupt the cell. \"\n",
    "        \"If you also want to stop the remote run, cancel it via your client.\"\n",
    "    )\n",
    "\n",
    "    start_poll = time.monotonic()\n",
    "    with Live(console=console, transient=False, refresh_per_second=8) as live:\n",
    "        try:\n",
    "            while True:\n",
    "                resp = client.ai_core_client.execution.get(execution_id=execution_id)\n",
    "                status = resp.status.name  # expecting an Enum-like object with .name\n",
    "\n",
    "                live.update(_render_status_panel(execution_id, status, created_at, note=note))\n",
    "\n",
    "                # Terminal states\n",
    "                if status in _TERMINAL_STATUSES:\n",
    "                    if status == \"COMPLETED\":\n",
    "                        console.print(Panel(Text(\"Run completed successfully âœ…\", style=\"bold green\"), border_style=\"green\"))\n",
    "                    elif status == \"ERROR\":\n",
    "                        console.print(Panel(Text(\"Run ended in ERROR âŒ\", style=\"bold red\"), border_style=\"red\"))\n",
    "                    elif status == \"STOPPED\":\n",
    "                        console.print(Panel(Text(\"Run was STOPPED â¹ï¸\", style=\"bold red\"), border_style=\"red\"))\n",
    "                    elif status == \"DEAD\":\n",
    "                        console.print(Panel(Text(\"Run is DEAD ðŸ’€\", style=\"bold red\"), border_style=\"red\"))\n",
    "                    return status\n",
    "\n",
    "                # Timeout?\n",
    "                if timeout is not None and (time.monotonic() - start_poll) > timeout:\n",
    "                    raise TimeoutError(\n",
    "                        f\"Polling timed out after {timeout} seconds (last status: {status}). \"\n",
    "                        \"You can interrupt the cell to stop polling, and cancel the remote run if needed.\"\n",
    "                    )\n",
    "\n",
    "                time.sleep(max(0.05, float(interval)))\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            console.print()  # newline\n",
    "            console.rule(\"[bold]Polling interrupted by user[/bold]\")\n",
    "            console.print(\n",
    "                \"- Polling has been stopped.\\n\",\n",
    "                style=\"italic\",\n",
    "            )\n",
    "            if cancel_callback:\n",
    "                try:\n",
    "                    cancel_callback(execution_id)\n",
    "                    console.print(\"Attempted to cancel the remote run via provided cancel_callback.\", style=\"bold yellow\")\n",
    "                except Exception as e:\n",
    "                    console.print(f\"Cancel callback raised an error: {e}\", style=\"red\")\n",
    "            return \"INTERRUPTED\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f98d0",
   "metadata": {},
   "source": [
    "## Helper Function Prompt Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3128e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def check_model_availability(latest_only: bool = True, filter_list = None):\n",
    "\n",
    "    url = client.ai_core_client.base_url + \"/lm/scenarios/foundation-models/models\"\n",
    "    response = requests.get(url=url, headers=client.request_header)\n",
    "    models = {}\n",
    "    for model in response.json()['resources']:\n",
    "        if  not any([scenario[\"executableId\"] == \"orchestration\" for scenario in model[\"allowedScenarios\"]]):\n",
    "            continue\n",
    "        if filter_list is not None and model[\"model\"] not in filter_list:\n",
    "            continue\n",
    "        models[model[\"model\"]] = []\n",
    "        for version in model[\"versions\"]:\n",
    "            if not any([v == \"text-generation\" for v in version.get(\"capabilities\", [])]):\n",
    "                continue\n",
    "            if not latest_only or version[\"isLatest\"]:\n",
    "                models[model[\"model\"]].append(version[\"name\"])\n",
    "            if version[\"isLatest\"]:\n",
    "                models[model[\"model\"]].append(\"latest\")\n",
    "\n",
    "    return [f'{k}:{v}' for k, vv in models.items() for v in vv if len(vv) > 0 ]\n",
    "\n",
    "filter_list=[\n",
    "    'gpt-5',\n",
    "    'gpt-5-mini',\n",
    "    'gpt-5-nano',\n",
    "    'gpt-4.1',\n",
    "    'gpt-4.1-mini',\n",
    "    'gpt-4.1-nano',\n",
    "    'gpt-4o',\n",
    "    'gpt-4o-mini',\n",
    "    'gemini-2.5-pro',\n",
    "    'gemini-2.5-flash',\n",
    "    'anthropic--claude-4-sonnet',\n",
    "    'anthropic--claude-4-opus'\n",
    "]\n",
    "\n",
    "SUPPORTED_MODELS = check_model_availability(filter_list=filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cdf0ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "SEMVER_PATTERN = re.compile(r'^[a-zA-Z0-9_-]+:[0-9]+\\.[0-9]+\\.[0-9]+$')\n",
    "SUPPORTED_METRICS = [\"LLMaaJ:Sem_Sim_1\", \"JSON_Match\"]\n",
    "\n",
    "def create_optim_config(metric: str,\n",
    "                  reference_model: str,\n",
    "                  targets: dict,\n",
    "                  dataset_path: str,\n",
    "                  scenario: str,\n",
    "                  include_few_shot_examples: bool,\n",
    "                  prompt: PromptTemplateSpec,\n",
    "                  artifact_id: str) -> str:\n",
    "    assert metric in SUPPORTED_METRICS, f\"Unsupported metric: {metric}. Supported metrics: {SUPPORTED_METRICS}\"\n",
    "    assert reference_model in SUPPORTED_MODELS, f\"Unsupported reference model: {reference_model}. Supported models: {SUPPORTED_MODELS}\"\n",
    "    #assert all(model in SUPPORTED_MODELS for model in targets.keys()), f\"Unsupported target models: {targets}. Supported models: {SUPPORTED_MODELS}\"\n",
    "    #assert all(bool(SEMVER_PATTERN.match(value)) for value in targets.values()), f\"Prompt target has to match '{SEMVER_PATTERN}'\"\n",
    "    input_parameters = [\n",
    "        ParameterBinding(key=\"dataset\", value=dataset_path),\n",
    "        ParameterBinding(key=\"optimizationMetric\", value=metric),\n",
    "        ParameterBinding(key=\"basePrompt\", value=f'{scenario}/{prompt[\"name\"]}:{prompt[\"version\"]}'),\n",
    "        ParameterBinding(key=\"baseModel\", value=reference_model),\n",
    "        ParameterBinding(key=\"targetModels\", value=','.join(targets.keys())),\n",
    "        ParameterBinding(key=\"includeFewShotExamples\", value=str(include_few_shot_examples).lower()),\n",
    "        ParameterBinding(key=\"targetPromptMapping\", value=\",\".join([f\"{k}={v}\" for k, v in targets.items()]))\n",
    "    ]\n",
    "    \n",
    "\n",
    "    input_artifacts = [InputArtifactBinding(key=\"prompt-data\", artifact_id = artifact_id)]\n",
    "\n",
    "    response = client.ai_core_client.configuration.create(\n",
    "        name = \"facility-classification-optimization\", # custom name of configuration\n",
    "        scenario_id = \"genai-optimizations\", # value from workflow\n",
    "        executable_id = \"genai-optimizations\", # value from workflow\n",
    "        resource_group = \"default\",\n",
    "        parameter_bindings = input_parameters,\n",
    "        input_artifact_bindings = input_artifacts\n",
    "    )\n",
    "\n",
    "    return response.id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b56f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "def fetch_results(execution_id):\n",
    "    response = client.ai_core_client.execution.get(execution_id = execution_id)\n",
    "    if response.status.name not in {'DEAD', 'COMPLETED'}:\n",
    "        raise RuntimeError('Execution not finished!')\n",
    "    path = f\"default/{execution_id}/result-data/results.json\"\n",
    "    encoded_path = quote(path, safe=\"\")\n",
    "    url = f\"{client.ai_core_client.base_url}/lm/dataset/files/{encoded_path}\"\n",
    "    headers = {\n",
    "        **client.request_header,\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()# results = response.json()\n",
    "\n",
    "\n",
    "def print_results_with_prompts(result):\n",
    "    print_prompt_template(PromptTemplateSpec.from_optimizer_result(result[\"origin_model\"]), addition='Baseline Prompt')\n",
    "    origin_model = result[\"origin_model\"]\n",
    "    table = Table(title=\"Performance\")\n",
    "    table.add_column(\"Model\", justify=\"right\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Pre Optimization\", style=\"magenta\")\n",
    "    table.add_column(\"Post Optimization\", justify=\"right\", style=\"green\")\n",
    "    table.add_row(origin_model[\"model_name\"], f'{origin_model[\"score\"]:.3f}', \"n/a - reference run\")\n",
    "    for m in result[\"target_models\"]:\n",
    "        if m['result_status'] not in {'failed'}:\n",
    "            table.add_row(m[\"model_name\"], f'{m[\"pre_optimization_score\"]:.3f}', f'{m[\"post_optimization_score\"]:.3f}')\n",
    "    for m in result[\"target_models\"]:\n",
    "        print_prompt_template(PromptTemplateSpec.from_optimizer_result(m), addition=m['model_name'])\n",
    "    console.print(table)\n",
    "\n",
    "def print_results_only(result):\n",
    "    origin_model = result[\"origin_model\"]\n",
    "    table = Table(title=\"Performance\")\n",
    "    table.add_column(\"Model\", justify=\"right\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Pre Optimization\", style=\"magenta\")\n",
    "    table.add_column(\"Post Optimization\", justify=\"right\", style=\"green\")\n",
    "    table.add_row(origin_model[\"model_name\"], f'{origin_model[\"score\"]:.3f}', \"n/a - reference run\")\n",
    "    for m in result[\"target_models\"]:\n",
    "        if m['result_status'] not in {'failed'}:\n",
    "            table.add_row(m[\"model_name\"], f'{m[\"pre_optimization_score\"]:.3f}', f'{m[\"post_optimization_score\"]:.3f}')\n",
    "    console.print(table)\n",
    "\n",
    "\n",
    "\n",
    "def print_logs(execution_id):\n",
    "    try:\n",
    "        fetch_results(execution_id, file_name='result-data/log.txt')\n",
    "    except HTTPError:\n",
    "        console.print(Panel(Text(f\"No logs found for {execution_id} âŒ\", style=\"bold red\"), border_style=\"red\"))\n",
    "    else:\n",
    "        console.print(Panel(Text(\"Run completed successfully âœ…\", style=\"bold green\"), border_style=\"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e59e14",
   "metadata": {},
   "source": [
    "# Demo Scenario\n",
    "\n",
    "Our Scenario for this hands-on session is an existing AI use-case tha supports a facility management in analysing messages the team receives from employees about issues in the office. \n",
    "For this sceraio we have an existing prompt as well as data sets for optimization and evaluation with messages and golden answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb538dca",
   "metadata": {},
   "source": [
    "## Step 1: Familiarize youself with the Demo Data\n",
    "\n",
    "Let's get familiar with the prompt and the data. You can find the basic prompt in the `prompts` folder stored as `facility_prompt_basic.yaml`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "deba5234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Basic prompt:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Basic prompt:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">system: |-\n",
       "    You are a helpful assistant\n",
       "\n",
       "user: |-\n",
       "    Giving the following message:\n",
       "    ---\n",
       "    <span style=\"font-weight: bold\">{{</span>?input<span style=\"font-weight: bold\">}}</span>\n",
       "    ---\n",
       "    Extract and return a json with the follwoing keys and values:\n",
       "    - <span style=\"color: #008000; text-decoration-color: #008000\">\"urgency\"</span> as one of `high`, `medium`, `low`\n",
       "    - <span style=\"color: #008000; text-decoration-color: #008000\">\"sentiment\"</span> as one of `negative`, `neutral`, `positive`\n",
       "    - <span style=\"color: #008000; text-decoration-color: #008000\">\"categories\"</span> Create a dictionary with categories as keys and boolean values <span style=\"font-weight: bold\">(</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>/<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>, \n",
       "    where the value indicates whether the category is one of the best matching support category tags from: \n",
       "    `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`, \n",
       "    `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`, \n",
       "    `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`, \n",
       "    `facility_management_issues`\n",
       "\n",
       "    Your complete message should be a valid json string that can be read directly and only contain the keys \n",
       "    mentioned in the list above. Never enclose it in ```json<span style=\"color: #808000; text-decoration-color: #808000\">...</span>```, no newlines, no unnessacary whitespaces.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "system: |-\n",
       "    You are a helpful assistant\n",
       "\n",
       "user: |-\n",
       "    Giving the following message:\n",
       "    ---\n",
       "    \u001b[1m{\u001b[0m\u001b[1m{\u001b[0m?input\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n",
       "    ---\n",
       "    Extract and return a json with the follwoing keys and values:\n",
       "    - \u001b[32m\"urgency\"\u001b[0m as one of `high`, `medium`, `low`\n",
       "    - \u001b[32m\"sentiment\"\u001b[0m as one of `negative`, `neutral`, `positive`\n",
       "    - \u001b[32m\"categories\"\u001b[0m Create a dictionary with categories as keys and boolean values \u001b[1m(\u001b[0m\u001b[3;92mTrue\u001b[0m/\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m, \n",
       "    where the value indicates whether the category is one of the best matching support category tags from: \n",
       "    `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`, \n",
       "    `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`, \n",
       "    `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`, \n",
       "    `facility_management_issues`\n",
       "\n",
       "    Your complete message should be a valid json string that can be read directly and only contain the keys \n",
       "    mentioned in the list above. Never enclose it in ```json\u001b[33m...\u001b[0m```, no newlines, no unnessacary whitespaces.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Basic prompt:\") \n",
    "basic_prompt = open(\"../../data/prompts/facility_prompt_basic.yaml\", \"r\").read()\n",
    "print(basic_prompt) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e223d09",
   "metadata": {},
   "source": [
    " Regarding golden sample data we have two data sets one will be used for evaluations and one for optimizations they can be found in the `data/evaluation` and the `data/optimization` folder respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1dda757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Example data entry:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Example data entry:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'[\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'        {\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                \"input\": \"Subject: Assistance Needed with Facility Management Coordination\\\\n\\\\nHi Support </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Team,\\\\n\\\\nI hope this message finds you well. My name is [Sender], and I\\'ve been utilizing Facility Solutions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Company for our office building\\'s management for the past year. Overall, I\\'ve been quite satisfied with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">services provided, but I\\\\u2019ve encountered an issue that I need your help with.\\\\n\\\\nRecently, I\\'ve noticed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">some inconsistencies in the coordination of our space utilization and security measures. Specifically, there have </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">been a few instances where the security protocols were not followed correctly, and the space allocation for our new</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">team members hasn\\'t been managed as efficiently as before. This has caused some disruptions in our daily </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operations.\\\\n\\\\nI haven\\'t taken any steps to address this issue internally yet, as I believe it would be best </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">handled by your team of experts. Could you please look into this matter and provide a solution to ensure that our </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">facility management runs smoothly again?\\\\n\\\\nThank you for your attention to this matter. I look forward to your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prompt assistance.\\\\n\\\\nBest regards,\\\\n[Sender]\",\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                \"reference\": \"{\\\\\"categories\\\\\": [\\\\\"facility_management_issues\\\\\", </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\\"quality_and_safety_concerns\\\\\"], \\\\\"sentiment\\\\\": \\\\\"neutral\\\\\", \\\\\"urgency\\\\\": \\\\\"medium\\\\\"}\",\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                \"json_schema_value\": {\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                        \"type\": \"object\",\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                        \"properties\": {\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                \"categories\": {\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                        \"type\": \"array\"\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                },\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                \"sentiment\": {\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                        \"type\": \"integer\"\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                },\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                \"urgency\": {\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                        \"type\": \"string\"\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                }\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                        },\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                        \"required\": [\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                \"categories\",\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                \"sentiment\",\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                                \"urgency\"\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                        ]\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'                }\\n'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'        },\\n'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'        \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'                \"input\": \"Subject: Assistance Needed with Facility Management Coordination\\\\n\\\\nHi Support \u001b[0m\n",
       "\u001b[32mTeam,\\\\n\\\\nI hope this message finds you well. My name is \u001b[0m\u001b[32m[\u001b[0m\u001b[32mSender\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, and I\\'ve been utilizing Facility Solutions \u001b[0m\n",
       "\u001b[32mCompany for our office building\\'s management for the past year. Overall, I\\'ve been quite satisfied with the \u001b[0m\n",
       "\u001b[32mservices provided, but I\\\\u2019ve encountered an issue that I need your help with.\\\\n\\\\nRecently, I\\'ve noticed \u001b[0m\n",
       "\u001b[32msome inconsistencies in the coordination of our space utilization and security measures. Specifically, there have \u001b[0m\n",
       "\u001b[32mbeen a few instances where the security protocols were not followed correctly, and the space allocation for our new\u001b[0m\n",
       "\u001b[32mteam members hasn\\'t been managed as efficiently as before. This has caused some disruptions in our daily \u001b[0m\n",
       "\u001b[32moperations.\\\\n\\\\nI haven\\'t taken any steps to address this issue internally yet, as I believe it would be best \u001b[0m\n",
       "\u001b[32mhandled by your team of experts. Could you please look into this matter and provide a solution to ensure that our \u001b[0m\n",
       "\u001b[32mfacility management runs smoothly again?\\\\n\\\\nThank you for your attention to this matter. I look forward to your \u001b[0m\n",
       "\u001b[32mprompt assistance.\\\\n\\\\nBest regards,\\\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mSender\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\",\\n'\u001b[0m,\n",
       "    \u001b[32m'                \"reference\": \"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\\"categories\\\\\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\\"facility_management_issues\\\\\", \u001b[0m\n",
       "\u001b[32m\\\\\"quality_and_safety_concerns\\\\\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \\\\\"sentiment\\\\\": \\\\\"neutral\\\\\", \\\\\"urgency\\\\\": \\\\\"medium\\\\\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\",\\n'\u001b[0m,\n",
       "    \u001b[32m'                \"json_schema_value\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'                        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\\n'\u001b[0m,\n",
       "    \u001b[32m'                        \"type\": \"object\",\\n'\u001b[0m,\n",
       "    \u001b[32m'                        \"properties\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'                                \"categories\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'                                        \"type\": \"array\"\\n'\u001b[0m,\n",
       "    \u001b[32m'                                \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n'\u001b[0m,\n",
       "    \u001b[32m'                                \"sentiment\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'                                        \"type\": \"integer\"\\n'\u001b[0m,\n",
       "    \u001b[32m'                                \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n'\u001b[0m,\n",
       "    \u001b[32m'                                \"urgency\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'                                        \"type\": \"string\"\\n'\u001b[0m,\n",
       "    \u001b[32m'                                \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'                        \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n'\u001b[0m,\n",
       "    \u001b[32m'                        \"required\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'                                \"categories\",\\n'\u001b[0m,\n",
       "    \u001b[32m'                                \"sentiment\",\\n'\u001b[0m,\n",
       "    \u001b[32m'                                \"urgency\"\\n'\u001b[0m,\n",
       "    \u001b[32m'                        \u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'                \u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "    \u001b[32m'        \u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Example data entry:\")\n",
    "with open(\"../../data/datasets/facility_eval_data.json\", \"r\") as input_file:\n",
    "    head = [next(input_file) for _ in range(25)]\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QcrTeIvD8Rgz",
   "metadata": {
    "id": "QcrTeIvD8Rgz"
   },
   "source": [
    "_We should have the facility-prompt yaml the test and the train data-set in the s3 store already.\n",
    "Does the store need the setup from the evaluation notebooks (eval- runs-prompts -testdata-dataset)?_\n",
    "_No orchestration config necessary - working directly with templates is possible directly_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3791b19a",
   "metadata": {},
   "source": [
    "## Step 2: Let's evaluate the current prompt with the dataset\n",
    "\n",
    "Let's evaluate the current prompt with the evaluation dataset for a given model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f1236",
   "metadata": {},
   "source": [
    "### Step 2.1: Upload the prompt to the prompt registry\n",
    "\n",
    "First let's evaluate our prompt and the existing placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b7e0d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ System Message â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> You are a helpful assistant                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m System Message \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m You are a helpful assistant                                                                                     \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ User Message â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> Giving the following message:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> ---                                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> {{?input}}                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> ---                                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> Extract and return a json with the follwoing keys and values:                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> - \"urgency\" as one of `high`, `medium`, `low`                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> - \"sentiment\" as one of `negative`, `neutral`, `positive`                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> - \"categories\" Create a dictionary with categories as keys and boolean values (True/False),                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> where the value indicates whether the category is one of the best matching support category tags from:          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`,                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`,             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`,            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> `facility_management_issues`                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> Your complete message should be a valid json string that can be read directly and only contain the keys         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m User Message \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m Giving the following message:                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m ---                                                                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m {{?input}}                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m ---                                                                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m Extract and return a json with the follwoing keys and values:                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m - \"urgency\" as one of `high`, `medium`, `low`                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m - \"sentiment\" as one of `negative`, `neutral`, `positive`                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m - \"categories\" Create a dictionary with categories as keys and boolean values (True/False),                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m where the value indicates whether the category is one of the best matching support category tags from:          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`,                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`,             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`,            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m `facility_management_issues`                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m Your complete message should be a valid json string that can be read directly and only contain the keys         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prompt template loaded successfully. Placeholders found are: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prompt template loaded successfully. Placeholders found are: \u001b[1m{\u001b[0m\u001b[32m'input'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_prompt_template = \"../../data/prompts/facility_prompt_basic.yaml\" # local path to the prompt template or Prompt Repository identifier\n",
    "\n",
    "\n",
    "prompt = load_prompt_template(base_prompt_template) # .escape_curly_brackets() if validation fails.\n",
    "print_prompt_template(prompt)\n",
    "print(f\"Prompt template loaded successfully. Placeholders found are: {prompt.placeholders}\")\n",
    "assert validate_prompt(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e05dde",
   "metadata": {},
   "source": [
    "Now let's upload the prompt to the prompt registry so that we can reference it during evaluation and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb49ed96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prompt present in registry under id <span style=\"color: #ffff00; text-decoration-color: #ffff00\">a6768190-6f4f-4f64-b3a5-ab95e0968c37</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prompt present in registry under id \u001b[93ma6768190-6f4f-4f64-b3a5-ab95e0968c37\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "=== Base Prompt ===\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "=== Base Prompt ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ System Message â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> You are a helpful assistant                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m System Message \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m You are a helpful assistant                                                                                     \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ User Message â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> Giving the following message:                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> ---                                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> {{?input}}                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> ---                                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> Extract and return a json with the follwoing keys and values:                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> - \"urgency\" as one of `high`, `medium`, `low`                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> - \"sentiment\" as one of `negative`, `neutral`, `positive`                                                       <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> - \"categories\" Create a dictionary with categories as keys and boolean values (True/False),                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> where the value indicates whether the category is one of the best matching support category tags from:          <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`,                     <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`,             <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`,            <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> `facility_management_issues`                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> Your complete message should be a valid json string that can be read directly and only contain the keys         <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.        <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€\u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32m User Message \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m Giving the following message:                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m ---                                                                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m {{?input}}                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m ---                                                                                                             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m Extract and return a json with the follwoing keys and values:                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m - \"urgency\" as one of `high`, `medium`, `low`                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m - \"sentiment\" as one of `negative`, `neutral`, `positive`                                                       \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m - \"categories\" Create a dictionary with categories as keys and boolean values (True/False),                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m where the value indicates whether the category is one of the best matching support category tags from:          \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m `emergency_repair_services`, `routine_maintenance_requests`, `quality_and_safety_concerns`,                     \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m `specialized_cleaning_services`, `general_inquiries`, `sustainability_and_environmental_practices`,             \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m `training_and_support_requests`, `cleaning_services_scheduling`, `customer_feedback_and_complaints`,            \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m `facility_management_issues`                                                                                    \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m Your complete message should be a valid json string that can be read directly and only contain the keys         \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.        \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_template = load_prompt_template(base_prompt_template)\n",
    "base_prompt_template_registry = groupID+\"-facility-classification-base:0.0.1\"  # name:version for the template in the registry\n",
    "prompt_template_name_registry, _, prompt_template_version = base_prompt_template_registry.partition(\":\")\n",
    "\n",
    "prompt = push_prompt_template(prompt_template=base_template,\n",
    "                              prompt_template_name_registry=prompt_template_name_registry,\n",
    "                              prompt_template_version=prompt_template_version,\n",
    "                              scenario=scenario,\n",
    "                              update=True\n",
    ")\n",
    "\n",
    "print(f\"Prompt present in registry under id {prompt['id']}\")\n",
    "\n",
    "print('\\n\\n=== Base Prompt ===')\n",
    "print_prompt_template(prompt[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31acf2f1",
   "metadata": {},
   "source": [
    "### Step 2.2: Upload the data set to the prepared object store\n",
    "\n",
    "Now let's validate our data set used for the evaluation and upload it to the object store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a38876a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Dataset uploaded to ai:<span style=\"color: #800080; text-decoration-color: #800080\">//default/T-63//</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">ai</span>:<span style=\"color: #800080; text-decoration-color: #800080\">//default/T-63/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">testdata</span> -&gt; Artifact ID: \n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">65e6df78-6255-4786-bbd2-af9110589bd2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Dataset uploaded to ai:\u001b[35m/\u001b[0m\u001b[35m/default/T-63/\u001b[0m\u001b[35m/\u001b[0m\u001b[95mai\u001b[0m:\u001b[35m/\u001b[0m\u001b[35m/default/T-63/\u001b[0m\u001b[95mtestdata\u001b[0m -> Artifact ID: \n",
       "\u001b[93m65e6df78-6255-4786-bbd2-af9110589bd2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_secret=\"default\" # secret name in the object store <you want to use to store the dataset\n",
    "dataset_local_path=\"../../data/datasets/facility_eval_data.json\" # local path to the dataset\n",
    "dataset_remote_path=groupID+\"/testdata/facility-classification-eval.json\" # remote path in the object store to store the dataset\n",
    "artifact_root_path=\"ai://default/\"+groupID+\"/\"\n",
    "dataset_path = upload_file(\n",
    "    secret=dataset_secret,\n",
    "    local_path=dataset_local_path,\n",
    "    remote_path=dataset_remote_path,\n",
    "    overwrite=True\n",
    "    )\n",
    "artifact = register_artifact(\n",
    "    artifact_name=\"genai-eval-simplified-test-data\",\n",
    "    artifact_kind=Artifact.Kind.OTHER,\n",
    "    artifact_root_path=artifact_root_path,\n",
    "    scenario=\"genai-evaluations\",\n",
    "    description=\"Artifact for evaluation flow\"\n",
    ")\n",
    "\n",
    "print(f\"Dataset uploaded to {artifact.url}/{dataset_path} -> Artifact ID: {artifact.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130225a",
   "metadata": {},
   "source": [
    "### Step 2.3: Configure and start the Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719715f6",
   "metadata": {},
   "source": [
    "#### Step 2.3.1: Check available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25d7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "993f9321",
   "metadata": {},
   "source": [
    "#### Step 2.3.2 Chech available metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072731c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8676b8ef",
   "metadata": {},
   "source": [
    "#### Step 2.3.3: Configure the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f806d80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Selected metrics: JSON Schema Match\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Selected metrics: JSON Schema Match\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Selected models: gpt-4o-mini:latest\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Selected models: gpt-4o-mini:latest\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Manual Selection of Metrics and Models\n",
    "selected_metrics_str = \"JSON Schema Match\"\n",
    "selected_models_str = targetModel #model name as listed in models endpoint\n",
    "\n",
    "test_data_path = f\"testdata/facility-classification-eval.json\" # specify the test data path here. For the full folder just specifying testdata will work\n",
    "test_datasets = json.dumps({'path': test_data_path, 'type': 'json'})\n",
    "metrics_list = selected_metrics_str\n",
    "models_list = selected_models_str\n",
    "print(f\"Selected metrics: {metrics_list}\")\n",
    "print(f\"Selected models: {models_list}\")\n",
    "variable_mapping = json.dumps({'json_schema_match/json_schema':'data/json_schema_value','prompt/input': 'data/input'}) # to map the question prompt variable to the entry in dataset.\n",
    "orchestration_deployment_url = orchestration_deployment.deployment_url # need to specify this to use a specific deployment id\n",
    "repetitions = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3939af01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'genai-eval-conf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'scenarioId'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'genai-evaluations'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'executableId'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'genai-evaluations-simplified'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'inputArtifactBindings'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'datasetFolder'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'artifactId'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'65e6df78-6255-4786-bbd2-af9110589bd2'</span><span style=\"font-weight: bold\">}]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'parameterBindings'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'repetitions'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'orchestrationDeploymentURL'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.ai.staging.eu-west-1.mlf-aws-dev.com/v2/inference/deployments/d15746656296bd06'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'metrics'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'JSON Schema Match'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'testDataset'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"path\": \"testdata/facility-classification-eval.json\", \"type\": \"json\"}'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'variableMapping'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"json_schema_match/json_schema\": \"data/json_schema_value\", \"prompt/input\": \"data/input\"}'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'promptTemplate'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'c37d3749-8e37-4b6a-a067-168c49bc8469'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'models'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini:latest'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'debugMode'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ON'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'genai-eval-conf'\u001b[0m,\n",
       "    \u001b[32m'scenarioId'\u001b[0m: \u001b[32m'genai-evaluations'\u001b[0m,\n",
       "    \u001b[32m'executableId'\u001b[0m: \u001b[32m'genai-evaluations-simplified'\u001b[0m,\n",
       "    \u001b[32m'inputArtifactBindings'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'datasetFolder'\u001b[0m, \u001b[32m'artifactId'\u001b[0m: \u001b[32m'65e6df78-6255-4786-bbd2-af9110589bd2'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'parameterBindings'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'repetitions'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'1'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'key'\u001b[0m: \u001b[32m'orchestrationDeploymentURL'\u001b[0m,\n",
       "            \u001b[32m'value'\u001b[0m: \u001b[32m'https://api.ai.staging.eu-west-1.mlf-aws-dev.com/v2/inference/deployments/d15746656296bd06'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'metrics'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'JSON Schema Match'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'testDataset'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"path\": \"testdata/facility-classification-eval.json\", \"type\": \"json\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'key'\u001b[0m: \u001b[32m'variableMapping'\u001b[0m,\n",
       "            \u001b[32m'value'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"json_schema_match/json_schema\": \"data/json_schema_value\", \"prompt/input\": \"data/input\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'promptTemplate'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'c37d3749-8e37-4b6a-a067-168c49bc8469'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'models'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'gpt-4o-mini:latest'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'debugMode'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'ON'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Response</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">201</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mResponse\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m201\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'46235a44-845a-4a68-9d48-ecd533b03386'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Configuration created'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'46235a44-845a-4a68-9d48-ecd533b03386'\u001b[0m, \u001b[32m'message'\u001b[0m: \u001b[32m'Configuration created'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  creating an AICORE Configuration\n",
    "import requests\n",
    "\n",
    "request_body = {\n",
    "    \"name\": \"genai-eval-conf\",\n",
    "    \"scenarioId\": \"genai-evaluations\",\n",
    "    \"executableId\": \"genai-evaluations-simplified\",\n",
    "    \"inputArtifactBindings\": [\n",
    "        {\n",
    "            \"key\": \"datasetFolder\",\n",
    "            \"artifactId\": artifact.id\n",
    "        }\n",
    "    ],\n",
    "    \"parameterBindings\": [\n",
    "        {\n",
    "            \"key\": \"repetitions\",\n",
    "            \"value\": repetitions\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"orchestrationDeploymentURL\",\n",
    "            \"value\": orchestration_deployment_url\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"metrics\",\n",
    "            \"value\": metrics_list\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"testDataset\",\n",
    "            \"value\": test_datasets\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"variableMapping\",\n",
    "            \"value\": variable_mapping\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"promptTemplate\",\n",
    "            \"value\": prompt[\"id\"]\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"models\",\n",
    "            \"value\": models_list\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"debugMode\",\n",
    "            \"value\": \"ON\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(request_body )\n",
    "\n",
    "def create_aicore_configuration():\n",
    "    headers = headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    #GET_CONFIGURATIONS_ENDPOINT = '/v2/lm/configurations'\n",
    "    request_url = client.ai_core_client.base_url + \"/lm/configurations\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            request_url, headers=headers, data=json.dumps(request_body), timeout=120\n",
    "        )\n",
    "        print(response)\n",
    "        if(response.status_code != 201):\n",
    "            raise\n",
    "        result = response.json()\n",
    "        print(result)\n",
    "        return result['id']\n",
    "    except:\n",
    "       print(\"Error occurred while attempting to create a Configuration\")\n",
    "       print(response.text)\n",
    "       raise\n",
    "        \n",
    "configuration_id = create_aicore_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c4dd1",
   "metadata": {},
   "source": [
    "#### Step 2.3.4: Start the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2dbce3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">response received is  <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Response</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "response received is  \u001b[1m<\u001b[0m\u001b[1;95mResponse\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m202\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e607b094e229abf3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Execution scheduled'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'UNKNOWN'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'targetStatus'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'COMPLETED'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'e607b094e229abf3'\u001b[0m, \u001b[32m'message'\u001b[0m: \u001b[32m'Execution scheduled'\u001b[0m, \u001b[32m'status'\u001b[0m: \u001b[32m'UNKNOWN'\u001b[0m, \u001b[32m'targetStatus'\u001b[0m: \u001b[32m'COMPLETED'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create an execution with the created configuration.\n",
    "\n",
    "import requests\n",
    "\n",
    "def create_execution():\n",
    "    headers = headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    #GET_EXECUTIONS_ENDPOINT = '/v2/lm/executions'\n",
    "    request_url = client.ai_core_client.base_url + \"/lm/executions\"\n",
    "    request_body = {\"configurationId\" : configuration_id} \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            request_url, headers=headers, data=json.dumps(request_body), timeout=120\n",
    "        )\n",
    "        print(\"response received is \", response)\n",
    "        result = response.json()\n",
    "        print(result)\n",
    "        return result['id']\n",
    "    except:\n",
    "        print(\"Error occurred while attempting to create an execution\")\n",
    "        raise\n",
    " \n",
    "\n",
    "execution_id = create_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f457cc7f",
   "metadata": {},
   "source": [
    "### 2.4: Check the results of your evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f7e5d",
   "metadata": {},
   "source": [
    "#### 2.4.1 Check the status of the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bcba82fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9726ddb7e54a7e836389b078390b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Run completed successfully âœ…</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m \u001b[1;32mRun completed successfully âœ…\u001b[0m                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETED'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poll_status(execution_id, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69969bb2",
   "metadata": {},
   "source": [
    "#### 2.4.2 Check logs of your evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82169b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d70dc03c",
   "metadata": {},
   "source": [
    "#### 2.4.3 Check results of your evalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb7b899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9af6556",
   "metadata": {},
   "source": [
    "## Step 3: Let's improve the prompt with the help of our prompt Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954cd98",
   "metadata": {},
   "source": [
    "### 3.1 Upload the optimization data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f88ce",
   "metadata": {},
   "source": [
    "#### 3.1.1 Upload the data set to the prepared object store\n",
    "Now let's upload the data set used for the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8c1a88db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Dataset uploaded to ai:<span style=\"color: #800080; text-decoration-color: #800080\">//default/T-63/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">testdata</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Dataset uploaded to ai:\u001b[35m/\u001b[0m\u001b[35m/default/T-63/\u001b[0m\u001b[95mtestdata\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_secret=\"default\" # secret name in the object store <you want to use to store the dataset\n",
    "dataset_local_path=\"../../data/datasets/facility_optim_data.json\" # local path to the dataset\n",
    "dataset_remote_path=groupID+\"/testdata/facility-classification-optim.json\" # remote path in the object store to store the dataset\n",
    "dataset_path = upload_file(\n",
    "    secret=dataset_secret,\n",
    "    local_path=dataset_local_path,\n",
    "    remote_path=dataset_remote_path,\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "print(f\"Dataset uploaded to {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4955d90c",
   "metadata": {},
   "source": [
    "#### 3.1.2 Create artifact for optimization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "97a707b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-&gt; Artifact I<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">D:7c7a</span>6084-84da-4f95-84f6-c21ddfdc7e3f\n",
       "</pre>\n"
      ],
      "text/plain": [
       "-> Artifact I\u001b[1;92mD:7c7a\u001b[0m6084-84da-4f95-84f6-c21ddfdc7e3f\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artifact_root_path=\"ai://default/\"+groupID+\"/\"\n",
    "artifact = register_artifact(\n",
    "    artifact_name=\"facility-classification-optimization-data\",\n",
    "    artifact_kind=Artifact.Kind.DATASET,\n",
    "    artifact_root_path=artifact_root_path,\n",
    "    scenario=\"genai-optimizations\",\n",
    "    description=\"Artifact for prompt optimization\"\n",
    ")\n",
    "\n",
    "print(\"-> Artifact ID:\" + artifact.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c31a46",
   "metadata": {},
   "source": [
    "#### 3.2 Configure and start the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48407ff9",
   "metadata": {},
   "source": [
    "### 3.2.1 Configure the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a879dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"prompt-optimization-demo\"\n",
    "\n",
    "base_prompt_template_registry = \"AI-161-\"+groupID+\"/\"+groupID+\"-facility-classification-base:0.0.1\"  # name:version for the template in the registry\n",
    "\n",
    "dataset_secret=\"default\" # secret name in the object store <you want to use to store the dataset\n",
    "dataset_remote_path=\"testdata/facility-classification-optim.json\" # remote path in the object store to store the dataset\n",
    "\n",
    "\n",
    "include_few_shot_examples = True # whether to include few shot examples in the prompt\n",
    "\n",
    "reference_model = \"gpt-4o:2024-08-06\"\n",
    "# Dictionary of models to optimize with their corresponding prompt template names under which the optimized prompt should be stored in the registry\n",
    "targets = {\n",
    "    targetModel : groupID+\"-facility-classification-optim:0.0.1\"\n",
    "}\n",
    "# Metric to use for optimization\n",
    "metric = \"JSON_Match\" # Semantic\n",
    "\n",
    "configuration_id = create_optim_config(metric=metric,\n",
    "                                 reference_model=reference_model,\n",
    "                                 targets=targets,\n",
    "                                 dataset_path=\"testdata/facility-classification-optim.json\",\n",
    "                                 scenario=scenario,\n",
    "                                 include_few_shot_examples=include_few_shot_examples,\n",
    "                                 prompt=prompt,\n",
    "                                 artifact_id=artifact.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f68eeb9",
   "metadata": {},
   "source": [
    "#### 3.2.2 Start the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "874173e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Execution started with ID: ef6844185c528f27\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Execution started with ID: ef6844185c528f27\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.ai_core_client.execution.create(\n",
    "    configuration_id = configuration_id, # Change this value.\n",
    "    resource_group = \"default\"\n",
    ")\n",
    "\n",
    "execution_id = response.id\n",
    "print('Execution started with ID:', execution_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f51c67c",
   "metadata": {},
   "source": [
    "### 3.3 Check your optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a4b7f",
   "metadata": {},
   "source": [
    "#### 3.3.1 Check the status of the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "023c05ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c198f3f268646bf82d1ee1d83867138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Run completed successfully âœ…</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m \u001b[1;32mRun completed successfully âœ…\u001b[0m                                                                                   \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETED'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poll_status(execution_id, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8805e99",
   "metadata": {},
   "source": [
    "#### 3.3.2 Check logs of your optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "741d0770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edecbc06d6bf4cb8b3423a90244bbaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Run is DEAD ðŸ’€</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[1;31mRun is DEAD ðŸ’€\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">todo print logs function\n",
       "</pre>\n"
      ],
      "text/plain": [
       "todo print logs function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_stat = poll_status(execution_id, client)\n",
    "if  p_stat == 'DEAD' or p_stat == 'COMPLETED':\n",
    "    print(\"todo print logs function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c7596",
   "metadata": {},
   "source": [
    "#### 3.3.3 Check results of your optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if poll_status(execution_id, client) == 'COMPLETED':\n",
    "    results = fetch_results(execution_id)\n",
    "    print_results_with_prompts(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85296509",
   "metadata": {},
   "source": [
    "## Step 4: Let's evaluate the optimized prompt with the evaluation service and our evaluation dataset\n",
    "\n",
    "Let's evaluate the curoptimized prompt with the evaluation dataset to compare pre and post optimization scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3059523",
   "metadata": {},
   "source": [
    "### Step 4.1: Configure and start the Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce35fe0",
   "metadata": {},
   "source": [
    "#### Step 4.1.1: Configure the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d7ad351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Selected metrics: JSON Schema Match\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Selected metrics: JSON Schema Match\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Selected models: gpt-4o-mini:latest\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Selected models: gpt-4o-mini:latest\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: https://api.ai.staging.eu-west-1.mlf-aws-dev.com/v2/lm/promptTemplates?name=T-63-facility-classification-optim%2F&version=%2F0.0.1&scenario=AI161-T-63&includeSpec=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m orchestration_deployment_url \u001b[38;5;241m=\u001b[39m orchestration_deployment\u001b[38;5;241m.\u001b[39mdeployment_url \u001b[38;5;66;03m# need to specify this to use a specific deployment id\u001b[39;00m\n\u001b[0;32m     13\u001b[0m repetitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m optim_prompt\u001b[38;5;241m=\u001b[39m\u001b[43mfetch_prompt_template\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAI161-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mgroupID\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mgroupID\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-facility-classification-optim/:/0.0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(optim_prompt)\n",
      "Cell \u001b[1;32mIn[26], line 98\u001b[0m, in \u001b[0;36mfetch_prompt_template\u001b[1;34m(prompt_template)\u001b[0m\n\u001b[0;32m     92\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: version,\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscenario\u001b[39m\u001b[38;5;124m\"\u001b[39m: scenario,\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincludeSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     }\n\u001b[0;32m     97\u001b[0m response \u001b[38;5;241m=\u001b[39m  requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders, params\u001b[38;5;241m=\u001b[39mbody)\n\u001b[1;32m---> 98\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\I588417\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1021\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1023\u001b[0m     )\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api.ai.staging.eu-west-1.mlf-aws-dev.com/v2/lm/promptTemplates?name=T-63-facility-classification-optim%2F&version=%2F0.0.1&scenario=AI161-T-63&includeSpec=True"
     ]
    }
   ],
   "source": [
    "# Manual Selection of Metrics and Models\n",
    "selected_metrics_str = \"JSON Schema Match\"\n",
    "selected_models_str = targetModel #model name as listed in models endpoint\n",
    "\n",
    "test_data_path = f\"testdata/facility-classification-eval.json\" # specify the test data path here. For the full folder just specifying testdata will work\n",
    "test_datasets = json.dumps({'path': test_data_path, 'type': 'json'})\n",
    "metrics_list = selected_metrics_str\n",
    "models_list = selected_models_str\n",
    "print(f\"Selected metrics: {metrics_list}\")\n",
    "print(f\"Selected models: {models_list}\")\n",
    "variable_mapping = json.dumps({'json_schema_match/json_schema':'data/json_schema_value','prompt/input': 'data/input'}) # to map the question prompt variable to the entry in dataset.\n",
    "orchestration_deployment_url = orchestration_deployment.deployment_url # need to specify this to use a specific deployment id\n",
    "repetitions = \"1\"\n",
    "\n",
    "optim_prompt=fetch_prompt_template(\"AI161-\"+groupID+\"/\"+groupID+\"-facility-classification-optim/:/0.0.1\")\n",
    "print(optim_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a1e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'genai-eval-conf'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'scenarioId'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'genai-evaluations'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'executableId'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'genai-evaluations-simplified'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'inputArtifactBindings'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'datasetFolder'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'artifactId'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'65e6df78-6255-4786-bbd2-af9110589bd2'</span><span style=\"font-weight: bold\">}]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'parameterBindings'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'repetitions'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'orchestrationDeploymentURL'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.ai.staging.eu-west-1.mlf-aws-dev.com/v2/inference/deployments/d15746656296bd06'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'metrics'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'JSON Schema Match'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'testDataset'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"path\": \"testdata/facility-classification-eval.json\", \"type\": \"json\"}'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'variableMapping'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"json_schema_match/json_schema\": \"data/json_schema_value\", \"prompt/input\": \"data/input\"}'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'promptTemplate'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'c37d3749-8e37-4b6a-a067-168c49bc8469'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'models'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini:latest'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'debugMode'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ON'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'genai-eval-conf'\u001b[0m,\n",
       "    \u001b[32m'scenarioId'\u001b[0m: \u001b[32m'genai-evaluations'\u001b[0m,\n",
       "    \u001b[32m'executableId'\u001b[0m: \u001b[32m'genai-evaluations-simplified'\u001b[0m,\n",
       "    \u001b[32m'inputArtifactBindings'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'datasetFolder'\u001b[0m, \u001b[32m'artifactId'\u001b[0m: \u001b[32m'65e6df78-6255-4786-bbd2-af9110589bd2'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'parameterBindings'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'repetitions'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'1'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'key'\u001b[0m: \u001b[32m'orchestrationDeploymentURL'\u001b[0m,\n",
       "            \u001b[32m'value'\u001b[0m: \u001b[32m'https://api.ai.staging.eu-west-1.mlf-aws-dev.com/v2/inference/deployments/d15746656296bd06'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'metrics'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'JSON Schema Match'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'testDataset'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"path\": \"testdata/facility-classification-eval.json\", \"type\": \"json\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'key'\u001b[0m: \u001b[32m'variableMapping'\u001b[0m,\n",
       "            \u001b[32m'value'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"json_schema_match/json_schema\": \"data/json_schema_value\", \"prompt/input\": \"data/input\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'promptTemplate'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'c37d3749-8e37-4b6a-a067-168c49bc8469'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'models'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'gpt-4o-mini:latest'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'debugMode'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'ON'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Response</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">201</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mResponse\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m201\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'46235a44-845a-4a68-9d48-ecd533b03386'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Configuration created'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'46235a44-845a-4a68-9d48-ecd533b03386'\u001b[0m, \u001b[32m'message'\u001b[0m: \u001b[32m'Configuration created'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  creating an AICORE Configuration\n",
    "import requests\n",
    "\n",
    "request_body = {\n",
    "    \"name\": \"genai-eval-conf\",\n",
    "    \"scenarioId\": \"genai-evaluations\",\n",
    "    \"executableId\": \"genai-evaluations-simplified\",\n",
    "    \"inputArtifactBindings\": [\n",
    "        {\n",
    "            \"key\": \"datasetFolder\",\n",
    "            \"artifactId\": artifact.id\n",
    "        }\n",
    "    ],\n",
    "    \"parameterBindings\": [\n",
    "        {\n",
    "            \"key\": \"repetitions\",\n",
    "            \"value\": repetitions\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"orchestrationDeploymentURL\",\n",
    "            \"value\": orchestration_deployment_url\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"metrics\",\n",
    "            \"value\": metrics_list\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"testDataset\",\n",
    "            \"value\": test_datasets\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"variableMapping\",\n",
    "            \"value\": variable_mapping\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"promptTemplate\",\n",
    "            \"value\": optim_prompt[\"id\"]\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"models\",\n",
    "            \"value\": models_list\n",
    "        },\n",
    "        {\n",
    "            \"key\": \"debugMode\",\n",
    "            \"value\": \"ON\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(request_body )\n",
    "\n",
    "def create_aicore_configuration():\n",
    "    headers = headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    #GET_CONFIGURATIONS_ENDPOINT = '/v2/lm/configurations'\n",
    "    request_url = client.ai_core_client.base_url + \"/lm/configurations\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            request_url, headers=headers, data=json.dumps(request_body), timeout=120\n",
    "        )\n",
    "        print(response)\n",
    "        if(response.status_code != 201):\n",
    "            raise\n",
    "        result = response.json()\n",
    "        print(result)\n",
    "        return result['id']\n",
    "    except:\n",
    "       print(\"Error occurred while attempting to create a Configuration\")\n",
    "       print(response.text)\n",
    "       raise\n",
    "        \n",
    "configuration_id = create_aicore_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296408d",
   "metadata": {},
   "source": [
    "#### Step 4.1.2: Start the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353f8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">response received is  <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Response</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "response received is  \u001b[1m<\u001b[0m\u001b[1;95mResponse\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m202\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e607b094e229abf3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Execution scheduled'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'UNKNOWN'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'targetStatus'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'COMPLETED'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'e607b094e229abf3'\u001b[0m, \u001b[32m'message'\u001b[0m: \u001b[32m'Execution scheduled'\u001b[0m, \u001b[32m'status'\u001b[0m: \u001b[32m'UNKNOWN'\u001b[0m, \u001b[32m'targetStatus'\u001b[0m: \u001b[32m'COMPLETED'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create an execution with the created configuration.\n",
    "\n",
    "import requests\n",
    "\n",
    "def create_execution():\n",
    "    headers = headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    #GET_EXECUTIONS_ENDPOINT = '/v2/lm/executions'\n",
    "    request_url = client.ai_core_client.base_url + \"/lm/executions\"\n",
    "    request_body = {\"configurationId\" : configuration_id} \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            request_url, headers=headers, data=json.dumps(request_body), timeout=120\n",
    "        )\n",
    "        print(\"response received is \", response)\n",
    "        result = response.json()\n",
    "        print(result)\n",
    "        return result['id']\n",
    "    except:\n",
    "        print(\"Error occurred while attempting to create an execution\")\n",
    "        raise\n",
    " \n",
    "\n",
    "post_eval_id = create_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db086a2",
   "metadata": {},
   "source": [
    "### 4.2: Check the results of your post evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf2457",
   "metadata": {},
   "source": [
    "#### 4.2.1 Check the status of the post evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e7e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9537c9997181479cb2767d02fd30d32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Run is DEAD ðŸ’€</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[1;31mRun is DEAD ðŸ’€\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'DEAD'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poll_status(post_eval_id, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb5e4c",
   "metadata": {},
   "source": [
    "#### 2.4.2 Check logs of your evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356be319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dcd2d68",
   "metadata": {},
   "source": [
    "#### 2.4.3 Check results of your evalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b060448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa81bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">response received is  <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Response</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "response received is  \u001b[1m<\u001b[0m\u001b[1;95mResponse\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m202\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e607b094e229abf3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Execution scheduled'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'UNKNOWN'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'targetStatus'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'COMPLETED'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'e607b094e229abf3'\u001b[0m, \u001b[32m'message'\u001b[0m: \u001b[32m'Execution scheduled'\u001b[0m, \u001b[32m'status'\u001b[0m: \u001b[32m'UNKNOWN'\u001b[0m, \u001b[32m'targetStatus'\u001b[0m: \u001b[32m'COMPLETED'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create an execution with the created configuration.\n",
    "\n",
    "import requests\n",
    "\n",
    "def create_execution():\n",
    "    headers = headers = {\n",
    "        **client.request_header,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    #GET_EXECUTIONS_ENDPOINT = '/v2/lm/executions'\n",
    "    request_url = client.ai_core_client.base_url + \"/lm/executions\"\n",
    "    request_body = {\"configurationId\" : configuration_id} \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            request_url, headers=headers, data=json.dumps(request_body), timeout=120\n",
    "        )\n",
    "        print(\"response received is \", response)\n",
    "        result = response.json()\n",
    "        print(result)\n",
    "        return result['id']\n",
    "    except:\n",
    "        print(\"Error occurred while attempting to create an execution\")\n",
    "        raise\n",
    " \n",
    "\n",
    "execution_id = create_execution()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Pd3wsKls4OS5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
